{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyONhEnosflDv2SSEBWcS1vD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tommasomncttn/NAS4CNN/blob/main/Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing "
      ],
      "metadata": {
        "id": "_bmtpvl1n5sN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn import datasets\n",
        "from sklearn.datasets import load_digits\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "yNWkDl4JnPWo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset "
      ],
      "metadata": {
        "id": "T6i4WgSHoBE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TensorizedDigits(Dataset):\n",
        "    \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, mode = \"train\", transforms = None, tensorized = True):\n",
        "        digits = load_digits()\n",
        "        if mode == \"train\":\n",
        "            self.data = digits.data[:1000].astype(np.float32)\n",
        "            self.targets = digits.target[:1000]\n",
        "        elif mode == \"val\":\n",
        "            self.data = digits.data[1000:1350].astype(np.float32)\n",
        "            self.targets = digits.target[1000:1350]\n",
        "        else:\n",
        "            self.data = digits.data[1350:].astype(np.float32)\n",
        "            self.targets = digits.target[1350:]\n",
        "\n",
        "        self.transforms = transforms\n",
        "\n",
        "        if tensorized:\n",
        "          self.transforms = TensorizedDigits.tensorization_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample_x = self.data[idx]\n",
        "        sample_y = self.targets[idx]\n",
        "        \n",
        "        if True:\n",
        "          sample_x, sample_y = self.transforms(sample_x, sample_y)\n",
        "        \n",
        "\n",
        "        return (sample_x, sample_y)\n",
        "\n",
        "    @staticmethod\n",
        "    def tensorization_transform(x, y):\n",
        "        \n",
        "        # reshape to get a valid input for a CNN\n",
        "        sample_x = x.reshape(1, 8, 8)\n",
        "        sample_y = y\n",
        "\n",
        "        # transform it to torch tensor to move them to cuda\n",
        "        if torch.cuda.is_available():\n",
        "\n",
        "          sample_x = torch.from_numpy(sample_x).to(\"cuda\")\n",
        "          sample_y = np.array(y)\n",
        "          sample_y = torch.from_numpy(sample_y).to(\"cuda\")\n",
        "\n",
        "\n",
        "        return sample_x, sample_y\n",
        "    \n",
        "    def visualize_datapoint(self, idx):\n",
        "\n",
        "      x,y = self.__getitem__( idx)\n",
        "      plt.imshow(x[0].cpu(), cmap=\"gray\")\n",
        "      plt.axis(\"off\")\n",
        "      plt.show()\n"
      ],
      "metadata": {
        "id": "tTaJR9yuoAnc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Module"
      ],
      "metadata": {
        "id": "gvKE7U34B_pL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiConfigCNN(nn.Module):\n",
        "    '''Conv2d → f(.) → Pooling → Flatten → Linear 1 → f(.) → Linear 2 → Softmax\n",
        "    '''\n",
        "    def __init__(self, cnn_i_N = 1, cnn_o_N = 8, cnn_k_size = 3, stride = 1, padding = 1, pool_k_size = 2, fnn_o_N = 10):\n",
        "        super(MultiConfigCNN, self).__init__()\n",
        "\n",
        "        self.cnn_i_N = cnn_i_N\n",
        "        self.cnn_o_N = cnn_o_N\n",
        "        self.cnn_k_size = cnn_k_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.pool_k_size = pool_k_size\n",
        "        self.fnn_o_N = fnn_o_N\n",
        "        \n",
        "        self.cnn =  nn.Conv2d(in_channels = cnn_i_N, out_channels = cnn_o_N, kernel_size = cnn_k_size, stride = stride, padding = padding)\n",
        "        self.activation1 = nn.ReLU() # or sigmoid, tanh, softplus, elu\n",
        "        self.pool = nn.MaxPool2d(kernel_size = pool_k_size) # or avg pool\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.linear1 = nn.Linear(in_features = self.compute_input_2_linear(), out_features = fnn_o_N)\n",
        "        self.activation2 = nn.ReLU() # or sigmoid, tanh, softplus, elu\n",
        "        self.linear2 = nn.Linear(in_features = fnn_o_N, out_features = 10)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "        self.nll = nn.NLLLoss(reduction=\"none\") \n",
        "    \n",
        "    def compute_input_2_linear(self):\n",
        "\n",
        "        # computing after convolution => [(W-K+2P)/S]+1\n",
        "        after_cnn_channels = self.cnn_o_N\n",
        "        after_cnn_height = after_cnn_width = ((8 - self.cnn_k_size + 2 * self.padding) / self.stride) + 1\n",
        "\n",
        "        # computing after pooling => fixed values stride=kernel_dimension, padding=0, dilation=1 => formula at end of https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n",
        "        after_pool_height = after_pool_width = ((after_cnn_height - self.pool_k_size) / self.pool_k_size ) + 1\n",
        "\n",
        "        # computing after flattening \n",
        "\n",
        "        return int(after_pool_height * after_pool_width * after_cnn_channels)\n",
        "\n",
        "    def classify(self, x):\n",
        "        \n",
        "        x = self.cnn(x)\n",
        "        x = self.activation1(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation2(x)\n",
        "        x = self.linear2(x)\n",
        "        log_prob = self.softmax(x)\n",
        "\n",
        "        y_pred = torch.argmax(log_prob, dim = 1).long()        \n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def forward(self, x, y, reduction=\"avg\"):\n",
        "        \n",
        "        x = self.cnn(x)\n",
        "        x = self.activation1(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation2(x)\n",
        "        x = self.linear2(x)\n",
        "        log_prob = self.softmax(x)\n",
        "\n",
        "        loss = self.nll(log_prob, y)\n",
        "\n",
        "        if reduction == \"sum\":\n",
        "            return loss.sum()\n",
        "\n",
        "        else:\n",
        "            return loss.mean()"
      ],
      "metadata": {
        "id": "Vp1stkTGB_Pu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference "
      ],
      "metadata": {
        "id": "p6Mp6NDjB6f8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize training, validation and test sets.\n",
        "train_data = TensorizedDigits(mode=\"train\")\n",
        "val_data = TensorizedDigits(mode=\"val\")\n",
        "test_data = TensorizedDigits(mode=\"test\")\n",
        "\n",
        "# Initialize data loaders.\n",
        "training_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "XGJo9-A8BiPs"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = MultiConfigCNN().to(\"cuda\")"
      ],
      "metadata": {
        "id": "AJN412WmNC8L"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (x,y) in training_loader:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  loss = cnn(x,y)\n",
        "  print(loss)\n",
        "  break"
      ],
      "metadata": {
        "id": "RmUwkh0-NMmd",
        "outputId": "a78efc3c-747b-46b1-e9e9-bf5da5ec8fd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 8, 8])\n",
            "torch.Size([64])\n",
            "tensor(2.4977, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iEZnW3YPN1CC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}